# Quality Dimension Generator

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.8+-blue.svg)](https://www.typescriptlang.org/)
[![Node.js](https://img.shields.io/badge/Node.js-18+-green.svg)](https://nodejs.org/)
[![MCP](https://img.shields.io/badge/MCP-1.6+-purple.svg)](https://modelcontextprotocol.io/)

A sophisticated **Model Context Protocol (MCP) server** that generates comprehensive quality evaluation dimensions and assessment criteria for any task or project. Transform vague requirements into precise, measurable quality standards with AI-powered analysis.

## ğŸ¯ What It Does

Quality Dimension Generator analyzes your tasks and automatically creates professional evaluation frameworks with:

- **ğŸ“Š Multi-dimensional Assessment** - Generate 1-10 customizable evaluation dimensions
- **ğŸ¯ Precise Scoring Criteria** - Clear 0-10 point scoring guidelines for each dimension  
- **ğŸ”„ Intelligent Task Refinement** - AI-powered task description optimization
- **ğŸ“ Professional Documentation** - Export ready-to-use evaluation standards
- **âš™ï¸ Flexible Configuration** - Adapt to different project types and quality standards

## ğŸŒŸ Key Features

### Core Capabilities
- **Intelligent Task Analysis** - Extract and refine core tasks from conversations
- **Dynamic Dimension Generation** - Create custom evaluation frameworks
- **Dual-Output Workflow** - Separate task refinement and dimension generation
- **Smart Deduplication** - Avoid duplicate work with content-based hashing
- **Timezone Intelligence** - Automatic detection and localization

### Quality Standards
- **Three-Tier Scoring** - 6 (acceptable), 8 (excellent), 10 (outstanding) guidelines
- **Full Range Flexibility** - Support for any 0-10 scoring within dimensions
- **Professional Output** - Markdown-formatted, publication-ready documentation
- **Configurable Strictness** - Adjust evaluation rigor based on project needs

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18 or higher
- TypeScript 5.8 or higher
- MCP-compatible client (Claude Desktop, VS Code, etc.)

### Installation

#### Option 1: NPM Package (Recommended)
```bash
npm install -g quality-dimension-generator
```

#### Option 2: From Source
```bash
git clone <repository-url>
cd quality-dimension-generator
npm install
npm run build
```

### Configuration

#### MCP Client Setup

Add to your MCP configuration file:

**Claude Desktop** (`claude_desktop_config.json`):
```json
{
  "mcpServers": {
    "quality-dimension-generator": {
      "command": "quality-dimension-generator",
      "args": [],
      "env": {
        "PROJECT_PATH": "/path/to/your/projects"
      }
    }
  }
}
```

**VS Code** (`settings.json`):
```json
{
  "mcp.servers": {
    "quality-dimension-generator": {
      "command": "quality-dimension-generator",
      "args": [],
      "cwd": "/path/to/your/project"
    }
  }
}
```

#### Project Configuration

The tool automatically creates a `.qdg` directory in your project:

```
.qdg/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ qdg.config.json     # Configuration settings
â””â”€â”€ tasks/
    â””â”€â”€ task_[timestamp]_[hash]/
        â””â”€â”€ task_[id]_output.md  # Generated evaluation standards
```

Configure dimensions and scoring in `.qdg/config/qdg.config.json`:
```json
{
  "settings": {
    "dimensionCount": 5,    // Number of evaluation dimensions (1-10)
    "expectedScore": 8      // Target quality level (0-10)
  }
}
```

## ğŸ“– Usage Guide

### Basic Workflow

#### 1. Analyze Your Task
```javascript
// Use the generate_task_analysis_prompt tool
{
  "userMessage": "Create a user authentication system",
  "conversationHistory": [/* previous messages */],
  "context": {/* additional context */}
}
```

#### 2. Generate Quality Dimensions
```javascript
// Use the generate_quality_dimensions_prompt tool
{
  "taskAnalysisJson": "{\"coreTask\": \"...\", \"taskType\": \"...\"}",
  "targetScore": 8,
  "projectPath": "/path/to/project"
}
```

#### 3. Save Evaluation Standards
```javascript
// Use the save_quality_dimensions tool
{
  "taskId": "task_1234567890_abcd1234",
  "projectPath": "/path/to/project",
  "refinedTaskDescription": "Refined task description from LLM",
  "dimensionsContent": "Complete evaluation dimensions from LLM"
}
```

### Advanced Usage

#### Custom Scoring Targets
Adjust evaluation strictness by setting target scores:
- **6-7**: Lenient evaluation for learning projects
- **8**: Standard professional quality (default)
- **9-10**: Strict evaluation for critical systems

#### Multiple Project Support
Each project maintains its own `.qdg` directory with independent configurations and task histories.

#### Intelligent Deduplication
The system automatically detects similar tasks using content hashing, preventing duplicate evaluation frameworks.

## ğŸ›  API Reference

### Tools Overview

| Tool | Purpose | Input | Output |
|------|---------|-------|--------|
| `generate_task_analysis_prompt` | Analyze user tasks | Message, history, context | Analysis prompt |
| `generate_quality_dimensions_prompt` | Create evaluation framework | Task analysis, config | Dimension prompt |
| `save_quality_dimensions` | Store evaluation standards | Task data, dimensions | Saved file path |
| `get_current_time_context` | Get temporal context | Locale, timezone | Time information |
| `diagnose_working_directory` | Debug environment | None | Diagnostic info |

### Tool Details

#### generate_task_analysis_prompt
Extracts and analyzes core tasks from user conversations.

**Parameters:**
- `userMessage` (string, required) - Primary user message
- `conversationHistory` (array, optional) - Previous conversation context
- `context` (object, optional) - Additional contextual information

**Returns:** Structured analysis prompt for LLM processing

#### generate_quality_dimensions_prompt
Generates comprehensive evaluation dimension prompts.

**Parameters:**
- `taskAnalysisJson` (string, required) - JSON result from task analysis
- `targetScore` (number, optional) - Target quality score (0-10, default: 8)
- `timezone` (string, optional) - Timezone for temporal context
- `locale` (string, optional) - Localization setting (default: "en-US")
- `projectPath` (string, optional) - Project directory path

**Returns:** Professional LLM prompt for dimension generation

#### save_quality_dimensions
Saves LLM-generated evaluation standards to project directory.

**Parameters:**
- `taskId` (string, required) - Unique task identifier
- `projectPath` (string, required) - Target project directory
- `refinedTaskDescription` (string, required) - LLM-refined task description
- `dimensionsContent` (string, required) - Generated evaluation dimensions
- `taskAnalysisJson` (string, optional) - Original task analysis for reference

**Returns:** Confirmation message with saved file location

## ğŸ’¡ Examples

### Software Development Project
```markdown
# Task: Build REST API
## Evaluation Dimensions:
1. **Code Quality** (0-10) - Architecture, patterns, maintainability
2. **Security** (0-10) - Authentication, data protection, vulnerability handling
3. **Performance** (0-10) - Response times, scalability, resource efficiency
4. **Documentation** (0-10) - API docs, code comments, user guides
5. **Testing** (0-10) - Unit tests, integration tests, coverage
```

### Content Creation Task
```markdown
# Task: Write Technical Blog Post
## Evaluation Dimensions:
1. **Technical Accuracy** (0-10) - Correctness, depth, current best practices
2. **Clarity & Readability** (0-10) - Structure, language, accessibility
3. **Practical Value** (0-10) - Actionable insights, real-world applicability
4. **Engagement** (0-10) - Interest level, examples, storytelling
5. **SEO & Discoverability** (0-10) - Keywords, structure, metadata
```

## ğŸ”§ Configuration Options

### Dimension Count
Control the number of evaluation dimensions (1-10):
```json
{
  "settings": {
    "dimensionCount": 3  // Fewer dimensions for simple tasks
  }
}
```

### Expected Score
Set quality expectations (0-10):
```json
{
  "settings": {
    "expectedScore": 9  // Higher standards for critical projects
  }
}
```

### Environment Variables
- `PROJECT_PATH` - Default project directory
- `QDG_DEBUG` - Enable debug logging
- `QDG_LOCALE` - Default localization setting

## ğŸ› Troubleshooting

### Common Issues

#### "No .qdg directories found"
**Solution:** Ensure you're running the tool from a project directory or provide the `projectPath` parameter.

#### "Failed to initialize .qdg directory"
**Solution:** Check write permissions for your project directory.

#### "Task analysis parsing failed"
**Solution:** Verify the task analysis JSON is properly formatted.

### Debug Mode
Enable detailed logging:
```bash
QDG_DEBUG=true quality-dimension-generator
```

### Diagnostic Tool
Use the built-in diagnostic tool to check your environment:
```javascript
// Use diagnose_working_directory tool
// Returns detailed environment information and configuration suggestions
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [contributing guidelines](CONTRIBUTING.md) for details.

### Development Setup
```bash
git clone <repository-url>
cd quality-dimension-generator
npm install
npm run dev
```

### Running Tests
```bash
npm test
npm run test:server
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built on the [Model Context Protocol](https://modelcontextprotocol.io/) standard
- Powered by TypeScript and Node.js ecosystem
- Inspired by quality engineering best practices

## ğŸ”— Resources

- [Model Context Protocol Documentation](https://modelcontextprotocol.io/docs)
- [TypeScript Handbook](https://www.typescriptlang.org/docs/)
- [Quality Assurance Best Practices](https://example.com/qa-best-practices)

---

**Ready to transform your quality standards?** Start generating professional evaluation dimensions today! ğŸš€

## ğŸš€ Usage Example

### Complete Workflow

1. **Extract Task from Conversation**
```javascript
// Call generate_task_analysis_prompt
{
  "userMessage": "I need to write a compelling product description for our new smartwatch",
  "conversationHistory": [...],
}
```

2. **Generate Quality Dimensions Prompt**
```javascript
// Call generate_quality_dimensions_prompt  
{
  "taskAnalysisJson": "{\"coreTask\": \"Write compelling smartwatch product description\", ...}",
  "projectPath": "/path/to/project",
  "targetScore": 8,
  "locale": "en-US"
}
```

3. **Process with LLM**
Take the generated prompt, send it to your LLM, and get:
- **Part 1**: Refined task description
- **Part 2**: Professional evaluation dimensions

4. **Save Results**
```javascript
// Call save_quality_dimensions
{
  "taskId": "task_1234567890_abc123",
  "projectPath": "/path/to/project",
  "refinedTaskDescription": "[LLM refined task description]",
  "dimensionsContent": "[LLM generated evaluation dimensions]"
}
```

### Example Output File
The saved file contains clean, focused content:

```markdown
# Task Description

## Core Task
Write a compelling product description for our new smartwatch

## Requirements
- Target audience: Tech-savvy consumers aged 25-40
- Length: 150-200 words
- Highlight key features: health monitoring, battery life, design
- Include emotional appeal and technical specifications

---

# Evaluation Dimensions

## Evaluation Dimensions (5 dimensions, 10 points each)

### 1. Content Accuracy (10 points)
- 8-10 points: All technical specifications are accurate and verifiable
- 6-7 points: Most information is accurate with minor discrepancies
- 4-5 points: Some inaccuracies present
- 0-3 points: Significant inaccuracies or misleading information

### 2. Persuasive Appeal (10 points)
- 8-10 points: Highly compelling, creates strong desire to purchase
- 6-7 points: Moderately persuasive with good appeal
- 4-5 points: Some persuasive elements present
- 0-3 points: Weak or ineffective persuasive appeal

[... additional dimensions ...]
```

## ğŸ”§ Installation & Setup

### Prerequisites
- Node.js 18+ 
- TypeScript
- Model Context Protocol compatible client

### Local Development
```bash
# Clone the repository
git clone https://github.com/magenie33/quality-dimension-generator.git
cd quality-dimension-generator

# Install dependencies
npm install

# Build the project
npm run build

# Run locally with MCP Inspector
npm run dev:legacy

# Or run with Smithery CLI
npm run dev
```

### Smithery.ai Deployment
This server is optimized for deployment on [Smithery.ai](https://smithery.ai):

1. Push your code to GitHub
2. Connect your repository to Smithery
3. Deploy with one click

The server includes:
- `smithery.yaml` configuration
- Proper module exports for Smithery
- Automatic timezone detection
- Stateless design for cloud deployment

## ğŸ¨ Design Principles

### Clean Output Focus
- **Minimal Formatting**: Output files contain only essential content
- **No Meta Information**: No timestamps, tool signatures, or usage instructions in final output
- **Pure Content**: Just the refined task description and evaluation dimensions

### Smart Task Management
- **Content-Based Deduplication**: Same task content generates same task ID
- **Hash-Based Identification**: Uses MD5 hash of core task elements
- **Automatic Directory Creation**: Seamless .qdg directory management

### Professional Standards
- **Evidence-Based Evaluation**: Each dimension includes clear scoring criteria
- **Flexible Scoring**: Supports decimal scores for precise evaluation
- **Standardized Format**: Consistent output format across all tasks

## ğŸ“Š Configuration Options

### Tool-Level Configuration
- `enabledTools`: Array of tools to enable
- `debug`: Enable debug logging
- `language`: Language preference (default: "en-US")

### Project-Level Configuration  
- `dimensionCount`: Number of evaluation dimensions (1-10)
- `expectedScore`: Target score level for guidance (0-10)

### Runtime Options
- Automatic timezone detection
- Configurable output localization
- Project-specific settings

## ğŸ” Advanced Features

### Intelligent Task Analysis
- Extracts core tasks from conversational input
- Identifies task type, domain, and complexity
- Suggests key elements and objectives
- Provides structured analysis for dimension generation

### Professional Dimension Generation
- Creates domain-specific evaluation criteria
- Includes detailed scoring rubrics
- Provides clear performance indicators
- Supports various task types and complexities

### Clean Output Management
- Generates human-readable markdown files
- Maintains version history through task IDs
- Enables easy sharing and collaboration
- Supports both single-file and multi-file workflows

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ› Issues & Support

If you encounter any issues or have questions, please [open an issue](https://github.com/magenie33/quality-dimension-generator/issues) on GitHub.

---

*Quality Dimension Generator - Professional task evaluation made simple*

Output: Formatted prompts + Task ID + Usage instructions
```

### 3. save_quality_dimensions â­ 
Save LLM-generated dual output results
```typescript
Input:
- taskId: string - Task ID
- projectPath: string - Project path
- refinedTaskDescription: string - LLM-refined task description (first stage output)
- dimensionsContent: string - LLM-generated evaluation dimensions (second stage output)
- taskAnalysisJson?: string - Original task analysis JSON (optional)

Output: âœ… Save success confirmation + File paths
```

### 4. get_current_time_context
Get current time context (auto-detect timezone)
```typescript
Input:
- timezone?: string - Timezone (optional, auto-detect system timezone if not specified)
- locale?: string - Localization settings

Output: Current time objective information, including auto-detected timezone
```

### 5. diagnose_working_directory
Diagnose working directory and environment
```typescript
Input: None

Output: Current working directory status and configuration recommendations
```

## ï¿½ å®Œæ•´å·¥ä½œæµç¨‹

### ğŸ”„ æ ‡å‡†ä¸‰æ­¥æµç¨‹

#### æ­¥éª¤1: åˆ†æä»»åŠ¡
```typescript
// ä»ç”¨æˆ·å¯¹è¯ä¸­æå–ä»»åŠ¡
const taskPrompt = await generate_task_analysis_prompt({
  userMessage: "åˆ›ä½œæ„ŸäººçŸ­æ–‡ã€Šæœ€åä¸€å°ä¿¡ã€‹å¹¶è¿›è¡Œè´¨é‡è¯„ä¼°"
});
// å°†æç¤ºè¯å‘ç»™LLMï¼Œè·å¾—ä»»åŠ¡åˆ†æJSON
```

#### æ­¥éª¤2: ç”Ÿæˆæç¤ºè¯
```typescript
// ç”Ÿæˆè¯„ä»·ç»´åº¦çš„æç¤ºè¯
const dimensionsPrompt = await generate_quality_dimensions_prompt({
  taskAnalysisJson: taskAnalysisResult,
  projectPath: "d:\\MEGA\\Projects\\mcp-test",
  targetScore: 8
});
// è¾“å‡º: æ ¼å¼åŒ–æç¤ºè¯ + ä»»åŠ¡IDï¼ˆå¦‚: task_1758354881691_3041bc0bï¼‰
```

#### æ­¥éª¤3: å¤„ç†LLMè¾“å‡ºå¹¶ä¿å­˜
```typescript
// LLMä¼šè¿”å›ä¸¤ä¸ªéƒ¨åˆ†ï¼š
// 1. ä»»åŠ¡æç‚¼ï¼ˆç¬¬ä¸€ç¯èŠ‚è¾“å‡ºï¼‰
// 2. è¯„ä»·ç»´åº¦ä½“ç³»ï¼ˆç¬¬äºŒç¯èŠ‚è¾“å‡ºï¼‰

// ä¿å­˜åŒè¾“å‡ºç»“æœ
const saveResult = await save_quality_dimensions({
  taskId: "task_1758354881691_3041bc0b",
  projectPath: "d:\\MEGA\\Projects\\mcp-test",
  refinedTaskDescription: "[LLMç¬¬ä¸€ä¸ªè¾“å‡º]",
  dimensionsContent: "[LLMç¬¬äºŒä¸ªè¾“å‡º]"
});
```

### ğŸ’¡ LLMè¾“å‡ºç¤ºä¾‹

**ç¬¬ä¸€ç¯èŠ‚è¾“å‡ºï¼ˆä»»åŠ¡æç‚¼ï¼‰**ï¼š
```
## ä»»åŠ¡æç‚¼

**æ ¸å¿ƒä»»åŠ¡**ï¼šåˆ›ä½œä¸€ç¯‡æ„ŸäººçŸ­æ–‡ã€Šæœ€åä¸€å°ä¿¡ã€‹ï¼Œé€šè¿‡ç»†è…»çš„æƒ…æ„Ÿæè¿°å’Œæ·±åˆ»çš„äººç‰©åˆ»ç”»ï¼Œä¼ è¾¾ç”Ÿå‘½çš„çè´µå’Œäººæ€§çš„ç¾å¥½ã€‚

**ä»»åŠ¡ç‰¹ç‚¹**ï¼š
- ç±»å‹ï¼šæƒ…æ„Ÿæ–‡å­¦åˆ›ä½œ
- å¤æ‚åº¦ï¼šä¸­é«˜ç­‰ï¼ˆ4/5ï¼‰
- ç›®æ ‡è¯»è€…ï¼šå¯»æ±‚æƒ…æ„Ÿå…±é¸£çš„æ–‡å­¦çˆ±å¥½è€…
- æ ¸å¿ƒä»·å€¼ï¼šè§¦åŠ¨å¿ƒçµï¼Œå¯å‘æ€è€ƒ

**å…³é”®è¦æ±‚**ï¼š
- æƒ…æ„ŸçœŸæŒšï¼Œé¿å…ç…½æƒ…
- äººç‰©å½¢è±¡ç«‹ä½“å¯ä¿¡
- è¯­è¨€ä¼˜ç¾æµç•…
- ä¸»é¢˜ç§¯æå‘ä¸Š
- ç»“æ„å®Œæ•´æœ‰å±‚æ¬¡
```

**ç¬¬äºŒç¯èŠ‚è¾“å‡ºï¼ˆè¯„ä»·ç»´åº¦ï¼‰**ï¼š
```
æ„ŸäººçŸ­æ–‡è¯„ä»·ç»´åº¦ä½“ç³»

ç»´åº¦1ï¼šæƒ…æ„Ÿæ·±åº¦ä¸æ„ŸæŸ“åŠ› (0-10åˆ†)
æè¿°ï¼šè¯„ä¼°æ–‡ç« çš„æƒ…æ„Ÿè¡¨è¾¾æ·±åº¦å’Œå¯¹è¯»è€…çš„æ„ŸæŸ“åŠ›
é‡è¦æ€§ï¼šæƒ…æ„Ÿæ·±åº¦æ˜¯æ„Ÿäººæ–‡å­¦çš„æ ¸å¿ƒï¼Œå†³å®šä½œå“çš„æ„ŸæŸ“åŠ›å’Œå…±é¸£æ•ˆæœ
è¯„åˆ†æŒ‡å¯¼ï¼š
- 10åˆ†ï¼šæƒ…æ„Ÿè¡¨è¾¾æ·±åˆ»çœŸæŒšï¼Œèƒ½å¼•å‘è¯»è€…å¼ºçƒˆçš„æƒ…æ„Ÿå…±é¸£å’Œæ·±å±‚æ€è€ƒ
- 8åˆ†ï¼šæƒ…æ„Ÿè¡¨è¾¾è¾ƒä¸ºæ·±åˆ»ï¼Œæœ‰è¾ƒå¼ºçš„æ„ŸæŸ“åŠ›ï¼Œèƒ½è§¦åŠ¨è¯»è€…å†…å¿ƒ
- 6åˆ†ï¼šæœ‰åŸºæœ¬çš„æƒ…æ„Ÿè¡¨è¾¾ï¼Œä½†æ·±åº¦å’Œæ„ŸæŸ“åŠ›ä¸€èˆ¬

ç»´åº¦2ï¼šäººç‰©åˆ»ç”»ä¸æ€§æ ¼å¡‘é€  (0-10åˆ†)
[ç»§ç»­å…¶ä»–4ä¸ªç»´åº¦...]
```

## ï¿½ é¡¹ç›®ç»“æ„

```
quality-dimension-generator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                 # MCPæœåŠ¡å™¨å…¥å£
â”‚   â”œâ”€â”€ schema.ts               # å·¥å…·Schemaå®šä¹‰
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ configManager.ts         # é…ç½®ç®¡ç†
â”‚       â”œâ”€â”€ qdgDirectoryManager.ts    # ç›®å½•ç®¡ç†
â”‚       â”œâ”€â”€ qualityDimensionGenerator.ts  # ç»´åº¦ç”Ÿæˆå™¨
â”‚       â”œâ”€â”€ taskExtractor.ts         # ä»»åŠ¡æå–å™¨
â”‚       â”œâ”€â”€ timeContextManager.ts    # æ—¶é—´ä¸Šä¸‹æ–‡ç®¡ç†
â”‚       â””â”€â”€ types.ts                 # ç±»å‹å®šä¹‰
â”œâ”€â”€ .qdg/                       # é…ç½®å’Œæ•°æ®ç›®å½•ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ qdg.config.json     # é¡¹ç›®é…ç½®
â”‚   â””â”€â”€ tasks/
â”‚       â””â”€â”€ [taskId]/
â”‚           â””â”€â”€ [taskId]_dimension.md  # ä¿å­˜çš„è¯„ä»·æ ‡å‡†
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## ï¿½ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…
```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd quality-dimension-generator

# å®‰è£…ä¾èµ–
npm install

# æ„å»ºé¡¹ç›®
npm run build
```

### è¿è¡Œ
```bash
# å¯åŠ¨MCPæœåŠ¡å™¨
npm start

# æˆ–ç›´æ¥è¿è¡Œ
node dist/index.js
```

### é…ç½®
ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ›å»º `.qdg` é…ç½®ç›®å½•ï¼Œé»˜è®¤é…ç½®ï¼š
```json
{
  "settings": {
    "dimensionCount": 5,
    "expectedScore": 8
  }
}
```

å¯ä»¥é€šè¿‡ä¿®æ”¹ `.qdg/config/qdg.config.json` è‡ªå®šä¹‰é…ç½®ï¼š
- `dimensionCount`: è¯„ä»·ç»´åº¦æ•°é‡ï¼ˆ1-10ï¼‰
- `expectedScore`: æœŸæœ›åˆ†æ•°ï¼ˆ0-10ï¼‰

**æ—¶åŒºè‡ªåŠ¨æ£€æµ‹**ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨è¿è¡Œç¯å¢ƒçš„æ—¶åŒºè®¾ç½®ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®ã€‚

## ğŸ“Š è¯„åˆ†ä½“ç³»

### 6-8-10 æŒ‡å¯¼ä½“ç³»
- **6åˆ†** - åŠæ ¼æ°´å¹³ï¼Œæ»¡è¶³åŸºæœ¬è¦æ±‚
- **8åˆ†** - ä¼˜ç§€æ°´å¹³ï¼Œè¶…å‡ºé¢„æœŸè¡¨ç°  
- **10åˆ†** - å“è¶Šæ°´å¹³ï¼Œä¸šç•Œæ ‡æ†è¡¨ç°

### å®é™…è¯„åˆ†èŒƒå›´
- **0-10åˆ†** - æ”¯æŒå®Œæ•´çš„ååˆ†åˆ¶è¯„åˆ†
- **çµæ´»ç²¾åº¦** - æ”¯æŒå°æ•°ç‚¹è¯„åˆ†ï¼ˆå¦‚7.5åˆ†ï¼‰

## ğŸ”§ é›†æˆæŒ‡å—

### Claude Desktop é…ç½®
```json
{
  "mcpServers": {
    "quality-dimension-generator": {
      "command": "node",
      "args": ["path/to/quality-dimension-generator/dist/index.js"],
      "cwd": "path/to/your-project"
    }
  }
}
```

### Cline/VSCode é…ç½®
```json
{
  "mcpServers": {
    "quality-dimension-generator": {
      "command": "node", 
      "args": ["dist/index.js"],
      "cwd": "path/to/quality-dimension-generator"
    }
  }
}
```

## ğŸ¨ è¾“å‡ºç¤ºä¾‹

### æœ€ç»ˆä¿å­˜çš„æ–‡ä»¶æ ¼å¼
```markdown
# è´¨é‡è¯„ä»·æ ‡å‡†

## ğŸ“‹ ä»»åŠ¡æç‚¼ï¼ˆç¬¬ä¸€ä¸ªç¯èŠ‚è¾“å‡ºï¼‰

**æ ¸å¿ƒä»»åŠ¡**ï¼šåˆ›ä½œä¸€ç¯‡æ„ŸäººçŸ­æ–‡ã€Šæœ€åä¸€å°ä¿¡ã€‹ï¼Œé€šè¿‡ç»†è…»çš„æƒ…æ„Ÿæè¿°å’Œæ·±åˆ»çš„äººç‰©åˆ»ç”»ï¼Œä¼ è¾¾ç”Ÿå‘½çš„çè´µå’Œäººæ€§çš„ç¾å¥½ã€‚

**ä»»åŠ¡ç‰¹ç‚¹**ï¼š
- ç±»å‹ï¼šæƒ…æ„Ÿæ–‡å­¦åˆ›ä½œ
- å¤æ‚åº¦ï¼šä¸­é«˜ç­‰ï¼ˆ4/5ï¼‰
- ç›®æ ‡è¯»è€…ï¼šå¯»æ±‚æƒ…æ„Ÿå…±é¸£çš„æ–‡å­¦çˆ±å¥½è€…
- æ ¸å¿ƒä»·å€¼ï¼šè§¦åŠ¨å¿ƒçµï¼Œå¯å‘æ€è€ƒ

**å…³é”®è¦æ±‚**ï¼š
- æƒ…æ„ŸçœŸæŒšï¼Œé¿å…ç…½æƒ…
- äººç‰©å½¢è±¡ç«‹ä½“å¯ä¿¡
- è¯­è¨€ä¼˜ç¾æµç•…
- ä¸»é¢˜ç§¯æå‘ä¸Š
- ç»“æ„å®Œæ•´æœ‰å±‚æ¬¡

---

## â­ è¯„ä»·ç»´åº¦ä½“ç³»ï¼ˆç¬¬äºŒä¸ªç¯èŠ‚è¾“å‡ºï¼‰

æ„ŸäººçŸ­æ–‡è¯„ä»·ç»´åº¦ä½“ç³»

ç»´åº¦1ï¼šæƒ…æ„Ÿæ·±åº¦ä¸æ„ŸæŸ“åŠ› (0-10åˆ†)
æè¿°ï¼šè¯„ä¼°æ–‡ç« çš„æƒ…æ„Ÿè¡¨è¾¾æ·±åº¦å’Œå¯¹è¯»è€…çš„æ„ŸæŸ“åŠ›
é‡è¦æ€§ï¼šæƒ…æ„Ÿæ·±åº¦æ˜¯æ„Ÿäººæ–‡å­¦çš„æ ¸å¿ƒï¼Œå†³å®šä½œå“çš„æ„ŸæŸ“åŠ›å’Œå…±é¸£æ•ˆæœ
è¯„åˆ†æŒ‡å¯¼ï¼š
- 10åˆ†ï¼šæƒ…æ„Ÿè¡¨è¾¾æ·±åˆ»çœŸæŒšï¼Œèƒ½å¼•å‘è¯»è€…å¼ºçƒˆçš„æƒ…æ„Ÿå…±é¸£å’Œæ·±å±‚æ€è€ƒ
- 8åˆ†ï¼šæƒ…æ„Ÿè¡¨è¾¾è¾ƒä¸ºæ·±åˆ»ï¼Œæœ‰è¾ƒå¼ºçš„æ„ŸæŸ“åŠ›ï¼Œèƒ½è§¦åŠ¨è¯»è€…å†…å¿ƒ
- 6åˆ†ï¼šæœ‰åŸºæœ¬çš„æƒ…æ„Ÿè¡¨è¾¾ï¼Œä½†æ·±åº¦å’Œæ„ŸæŸ“åŠ›ä¸€èˆ¬

ç»´åº¦2ï¼šäººç‰©åˆ»ç”»ä¸æ€§æ ¼å¡‘é€  (0-10åˆ†)
æè¿°ï¼šè¯„ä¼°æ–‡ç« ä¸­äººç‰©å½¢è±¡çš„ç«‹ä½“æ€§å’Œæ€§æ ¼å¡‘é€ çš„æˆåŠŸç¨‹åº¦
é‡è¦æ€§ï¼šç”ŸåŠ¨çš„äººç‰©å½¢è±¡æ˜¯æƒ…æ„Ÿå…±é¸£çš„è½½ä½“ï¼Œå†³å®šæ•…äº‹çš„å¯ä¿¡åº¦
è¯„åˆ†æŒ‡å¯¼ï¼š
- 10åˆ†ï¼šäººç‰©å½¢è±¡é²œæ˜ç«‹ä½“ï¼Œæ€§æ ¼ç‰¹å¾çªå‡ºï¼Œè¡Œä¸ºé€»è¾‘ä¸€è‡´
- 8åˆ†ï¼šäººç‰©åˆ»ç”»è¾ƒä¸ºæˆåŠŸï¼Œæœ‰ä¸€å®šçš„ä¸ªæ€§ç‰¹å¾
- 6åˆ†ï¼šäººç‰©å½¢è±¡åŸºæœ¬æ¸…æ™°ï¼Œä½†ç¼ºä¹æ·±åº¦å’Œç‰¹è‰²

[ç»§ç»­å…¶ä»–3ä¸ªç»´åº¦...]

---

## ğŸ“Š ä½¿ç”¨è¯´æ˜

**ä»»åŠ¡ID**: task_1758354881691_3041bc0b
**ç”Ÿæˆæ—¶é—´**: 2025/9/20 16:30:15

**è¯„åˆ†æ–¹å¼**: æ¯ä¸ªç»´åº¦å¯ç»™0-10åˆ†ä»»æ„æ•°å­—ï¼ˆåŒ…æ‹¬å°æ•°ç‚¹ï¼‰
**å‚è€ƒæ ‡å‡†**: 6åˆ†åŠæ ¼ã€8åˆ†ä¼˜ç§€ã€10åˆ†å“è¶Š
**æœ€ç»ˆåˆ†æ•°**: æ‰€æœ‰ç»´åº¦å¾—åˆ†çš„å¹³å‡å€¼

**çŠ¶æ€**: âœ… ä»»åŠ¡æç‚¼å’Œè¯„ä»·æ ‡å‡†å·²å®Œæˆï¼Œå¯å¼€å§‹æ‰§è¡Œä»»åŠ¡

---

*Quality Dimension Generator - åŒç¯èŠ‚è¾“å‡ºå®Œæ•´ç‰ˆ*
```

## ğŸ” å¼€å‘å’Œè°ƒè¯•

### å¼€å‘æ¨¡å¼
```bash
# ç›‘å¬æ–‡ä»¶å˜åŒ–ï¼Œè‡ªåŠ¨é‡æ–°æ„å»º
npm run dev
```

### æµ‹è¯•å·¥å…·
```bash
# ä½¿ç”¨MCP Inspectoræµ‹è¯•
npm run inspector
```

### è°ƒè¯•æ—¥å¿—
æœåŠ¡å™¨å¯åŠ¨æ—¶ä¼šæ˜¾ç¤ºï¼š
```
ğŸš€ Quality Dimension Generator MCP Server running on stdio
```

## âœ¨ æ ¸å¿ƒä¼˜åŠ¿

### ğŸ¯ **èŒè´£åˆ†ç¦»è®¾è®¡**
- **å·¥å…·1**: ä¸“é—¨ç”Ÿæˆæç¤ºè¯ï¼Œåˆ›å»ºä»»åŠ¡è®°å½•
- **å·¥å…·2**: ä¸“é—¨ä¿å­˜LLMçš„åŒè¾“å‡ºç»“æœ
- **æ¸…æ™°æµç¨‹**: æç¤ºè¯ç”Ÿæˆ â†’ LLMå¤„ç† â†’ ç»“æœä¿å­˜

### ğŸ“‹ **åŒç¯èŠ‚è¾“å‡º**
- **ç¬¬ä¸€ç¯èŠ‚**: LLMæç‚¼å’Œä¼˜åŒ–ä»»åŠ¡æè¿°
- **ç¬¬äºŒç¯èŠ‚**: LLMç”Ÿæˆå…·ä½“è¯„ä»·ç»´åº¦æ ‡å‡†
- **å®Œæ•´ä¿å­˜**: ä»»åŠ¡+è¯„ä»·æ ‡å‡†çš„å®Œæ•´æ–‡æ¡£

### ğŸ”„ **æ™ºèƒ½ç®¡ç†**
- **ä»»åŠ¡å»é‡**: åŸºäºå†…å®¹hashçš„æ™ºèƒ½å»é‡
- **ç›®å½•ç®¡ç†**: è‡ªåŠ¨åˆ›å»ºå’Œç®¡ç†.qdgç»“æ„
- **é…ç½®é©±åŠ¨**: çµæ´»çš„é¡¹ç›®çº§é…ç½®

## ğŸ“‹ æŠ€æœ¯ç‰¹æ€§

- **TypeScript** - å®Œæ•´çš„ç±»å‹å®‰å…¨
- **MCPåè®®** - æ ‡å‡†çš„Model Context Protocolå®ç°
- **ESæ¨¡å—** - ç°ä»£åŒ–çš„æ¨¡å—ç³»ç»Ÿ
- **æ™ºèƒ½å»é‡** - MD5 hashé˜²é‡å¤ä»»åŠ¡
- **æ—¶åŒºè‡ªåŠ¨æ£€æµ‹** - æ— éœ€é…ç½®ï¼Œè‡ªåŠ¨é€‚åº”è¿è¡Œç¯å¢ƒ
- **Markdownè¾“å‡º** - ç»“æ„åŒ–çš„äººç±»å‹å¥½è¾“å‡º

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤å˜æ›´
4. åˆ›å»º Pull Request

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ†˜ æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤ [Issue](https://github.com/your-repo/quality-dimension-generator/issues)ã€‚

---

**Quality Dimension Generator** - åŒç¯èŠ‚è¾“å‡ºï¼Œä¸“ä¸šè´¨é‡è¯„ä»· ğŸ¯